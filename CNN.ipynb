{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers \r\n",
    "from tensorflow.keras.datasets import mnist"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "x_train4D = x_train.reshape(60000, 28, 28, 1).astype('float32')\r\n",
    "x_test4D = x_test.reshape(10000, 28, 28, 1).astype('float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "x_train4D_normalize = x_train4D / 255\r\n",
    "x_test4D_normalize = x_test4D / 255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# 以 Onehot Encoding 轉換 label\r\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train)\r\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "# 建立CNN model\r\n",
    "\r\n",
    "# 建立卷積層1\r\n",
    "# 輸入數字影像 28x28 的大小，執行一次卷積運算，產生 16 個影像，卷積運算不會改變影像大小，結果還是 28x28\r\n",
    "model = tf.keras.Sequential()\r\n",
    "model.add(layers.Conv2D(filters=16,\r\n",
    "                         kernel_size=(5, 5),\r\n",
    "                         padding='same',          # 讓卷積運算產生的影像大小不變\r\n",
    "                         input_shape=(28, 28, 1), # input_shape(長, 寬, channel)\r\n",
    "                         activation='relu')\r\n",
    ")\r\n",
    "\r\n",
    "# 建立池化層\r\n",
    "# 輸入參數 pool_size=(2, 2)，執行第一次縮減取樣，將 16 個 28x28 影像，縮小為 16 個 14x14 的影像\r\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\r\n",
    "\r\n",
    "# 建立卷積層2\r\n",
    "# 執行第二次卷積運算，將原本的 16 個影像，轉換為 36 個影像，卷積運算不會改變影像大小，結果還是 14x14\r\n",
    "model.add(layers.Conv2D(filters=36,\r\n",
    "                        kernel_size=(5, 5),\r\n",
    "                        padding='same',\r\n",
    "                        activation='relu')\r\n",
    ")\r\n",
    "\r\n",
    "# 建立池化層2，並加入Dropout 避免 overfitting\r\n",
    "# 執行第二次縮減取樣，將 36 個 14x14 的影像，縮小為 36 個 7x7 的影像\r\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(layers.Dropout(0.25))\r\n",
    "\r\n",
    "# 建立神經網路 (平坦層, 隱藏層, 輸出層)\r\n",
    "# 建立平坦層\r\n",
    "# 根據池化層2 的結果，共36 個 7x7 影像，轉換為 1維向量，長度是 36x7x7=1764，也就是 1764 個 float，正好對應到 1764 個神經元\r\n",
    "model.add(layers.Flatten())\r\n",
    "\r\n",
    "# 建立隱藏層，共有 128 個神經元\r\n",
    "model.add(layers.Dense(128, activation='relu'))\r\n",
    "\r\n",
    "# 加入 Dropout(0.5)\r\n",
    "# 每次訓練迭代時，會隨機在神經網路中，放棄 50% 的神經元，以避免 overfitting\r\n",
    "model.add(layers.Dropout(0.5))\r\n",
    "\r\n",
    "# 建立輸出層\r\n",
    "# 共 10 個神經元，對應 0~9 共 10 個數字，並使用 softmax 激活函數進行轉換\r\n",
    "model.add(layers.Dense(10, activation='softmax'))\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 14, 36)        14436     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 7, 7, 36)          0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 7, 7, 36)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1764)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               225920    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 242,062\n",
      "Trainable params: 242,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "model.compile(\r\n",
    "    loss='categorical_crossentropy',\r\n",
    "    optimizer='adam',\r\n",
    "    metrics=['accuracy']\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "train_hisyory = model.fit(x=x_train4D_normalize, y=y_train_onehot, batch_size=300, epochs=20, validation_split=0.2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "160/160 [==============================] - 29s 179ms/step - loss: 0.9591 - accuracy: 0.6921 - val_loss: 0.0977 - val_accuracy: 0.9728\n",
      "Epoch 2/20\n",
      "160/160 [==============================] - 31s 193ms/step - loss: 0.1494 - accuracy: 0.9555 - val_loss: 0.0686 - val_accuracy: 0.9799\n",
      "Epoch 3/20\n",
      "160/160 [==============================] - 30s 187ms/step - loss: 0.1048 - accuracy: 0.9698 - val_loss: 0.0530 - val_accuracy: 0.9845\n",
      "Epoch 4/20\n",
      "160/160 [==============================] - 29s 180ms/step - loss: 0.0874 - accuracy: 0.9743 - val_loss: 0.0467 - val_accuracy: 0.9858\n",
      "Epoch 5/20\n",
      "160/160 [==============================] - 30s 187ms/step - loss: 0.0709 - accuracy: 0.9780 - val_loss: 0.0390 - val_accuracy: 0.9894\n",
      "Epoch 6/20\n",
      "160/160 [==============================] - 31s 195ms/step - loss: 0.0603 - accuracy: 0.9816 - val_loss: 0.0396 - val_accuracy: 0.9888\n",
      "Epoch 7/20\n",
      "160/160 [==============================] - 30s 190ms/step - loss: 0.0536 - accuracy: 0.9839 - val_loss: 0.0353 - val_accuracy: 0.9901\n",
      "Epoch 8/20\n",
      "160/160 [==============================] - 28s 174ms/step - loss: 0.0482 - accuracy: 0.9860 - val_loss: 0.0348 - val_accuracy: 0.9909\n",
      "Epoch 9/20\n",
      "160/160 [==============================] - 30s 187ms/step - loss: 0.0452 - accuracy: 0.9864 - val_loss: 0.0351 - val_accuracy: 0.9901\n",
      "Epoch 10/20\n",
      "160/160 [==============================] - 32s 200ms/step - loss: 0.0384 - accuracy: 0.9880 - val_loss: 0.0330 - val_accuracy: 0.9902\n",
      "Epoch 11/20\n",
      "160/160 [==============================] - 33s 206ms/step - loss: 0.0366 - accuracy: 0.9888 - val_loss: 0.0323 - val_accuracy: 0.9920\n",
      "Epoch 12/20\n",
      "160/160 [==============================] - 29s 184ms/step - loss: 0.0324 - accuracy: 0.9908 - val_loss: 0.0331 - val_accuracy: 0.9914\n",
      "Epoch 13/20\n",
      "160/160 [==============================] - 33s 203ms/step - loss: 0.0336 - accuracy: 0.9886 - val_loss: 0.0354 - val_accuracy: 0.9913\n",
      "Epoch 14/20\n",
      "160/160 [==============================] - 28s 177ms/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 0.0294 - val_accuracy: 0.9924\n",
      "Epoch 15/20\n",
      "160/160 [==============================] - 28s 176ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 0.0295 - val_accuracy: 0.9918\n",
      "Epoch 16/20\n",
      "160/160 [==============================] - 28s 175ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0285 - val_accuracy: 0.9921\n",
      "Epoch 17/20\n",
      "160/160 [==============================] - 28s 176ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0297 - val_accuracy: 0.9929\n",
      "Epoch 18/20\n",
      "160/160 [==============================] - 27s 169ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.0290 - val_accuracy: 0.9929\n",
      "Epoch 19/20\n",
      "160/160 [==============================] - 27s 169ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0303 - val_accuracy: 0.9927\n",
      "Epoch 20/20\n",
      "160/160 [==============================] - 27s 171ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0291 - val_accuracy: 0.9924\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "score = model.evaluate(x_test4D_normalize, y_test_onehot)\r\n",
    "print(\"Accuracy:{}%\".format(score[1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0183 - accuracy: 0.9943\n",
      "Accuracy:0.9943000078201294%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('env_1': conda)"
  },
  "interpreter": {
   "hash": "2416d103c63596454780769ea8d722882e3b9e5b984e9162296a4b6b08edade2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}